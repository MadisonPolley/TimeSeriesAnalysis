---
title: "Stat 349 Fall 2020"
subtitle: "Final Project Report"
author: 
  - "Madison Polley"
  - "Juliana Brandt"
  - "Anushka Prakash"
date: "December 14, 2020"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment = NA)

companies = c("AXP", "BIIB", "BKNG", "BLK", "CVS", "DHR", "EXC", "GOOG", "MA", "MDLZ", "MO", "SBUX", "ZION", "VMC", "VLO", "TSN", "SNA", "NCLH", "MAA", "MDT", "JNPR", "FE", "EA", "DLTR")

# Load libraries and set global parameters
library(sandwich)
library(ggplot2)
library(dplyr)
library(tidyr)
library(data.table)
library(corrplot)
library(gridExtra)
library(forecast)
library(tseries)
library(TSA)
library(TTR)
library(dygraphs)
library(assertthat)
library(xts)
library(readxl)
library(lmtest)
library(MESS)
```

# Dataset 1: AXP, 1/3/2006 - 11/19/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.

data = read_excel("MadisonPolley1.xlsx", sheet = "AXP")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for AXP is ARIMA(0,2,2).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.

data = read_excel("MadisonPolley1.xlsx", sheet = "AXP")[-1,]
plot(data$Close[2600:3400])
plot(data$NegLog[2600:3400], type = 'o')
slice1 = data[2600:3395, 8]
slice1.last5 = data[(3396:3400), 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

(i). For AXP, we split the data from 2600 to 3400 based on the plot of the "Close" data. The best model for the subset of AXP is ARIMA(0,0,0).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of AXP, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 **GARCH** ONLY in this.

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,2,2))

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,2). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(0,2) with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 **GARCH** ONLY in this.

model=arima(slice1,order=c(0,0,0))

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this GARCH model  is  the  final  model is because all of the coefficiants are significant and the model had relative convergence. 
We chose this model for this stock as the final model because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf.

## 1.4 Some diagnostic results

### Full Model


```{r echo=FALSE}

model=arima(data_without.last.five,order=c(0,2,2))


data = read_excel("MadisonPolley1.xlsx", sheet = "AXP")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```

Here we can see in the Decomposition plot, the trend of the AXP data is generally increasing with some seasonality. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. Finally, with a skewness 0f -0.585 and a kurtosis value of 14.288, we can definitively say the residuals are not normal.


### Partial Model

```{r echo=FALSE}

model=arima(slice1,order=c(0,0,0))

data = read_excel("MadisonPolley1.xlsx", sheet = "AXP")[-1,]
ts = ts(data$Close[2600:3400], frequency = 253, start = c(2016, 5, 3))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```

Here we can see in the Decomposition plot, the trend of the subset of AXP data is generally increasing with some seasonality. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. With a skewness value 0f -0.24, the data is not particularly skewed. With the kurtosis value of 7.198, we can definitively say the residuals are not normal.

# Dataset 2: BIIB, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.


data = read_excel("MadisonPolley1.xlsx", sheet = "BIIB")[-1,8]
#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(data_without.last.five,order=c(4,2,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)

```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for BIIB is ARIMA(4,2,1).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.

data = read_excel("MadisonPolley1.xlsx", sheet = "BIIB")[-1,]
plot(data$Close)
plot(data$Close[750:1700])
plot(data$NegLog[750:1700], type = 'o')
slice1 = data[750:1695, 8]
slice1.last5 = data[1696:1700, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
```

(i). For BIIB, we split the data from 750 to 1700 based on the plot of the "Close" data. The best model for the subset of BIIB is ARIMA(0,2,2).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of BIIB, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 **GARCH** ONLY in this.

model=arima(data_without.last.five,order=c(4,2,1))

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(0,2) with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 **GARCH** ONLY in this.

model=arima(slice1,order=c(0,2,2))

g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this GARCH model  is  the  final  model is because all of the coefficiants are significant and the model had relative convergence. 
We chose this model for this stock as the final model because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf.

## 1.4 Some diagnostic results

### Full Model

```{r echo=FALSE}
model=arima(data_without.last.five,order=c(0,2,2))


data = read_excel("MadisonPolley1.xlsx", sheet = "BIIB")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/3)) 
qqline((model$residuals)^(1/3))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 

Here we can see in the Decomposition plot, the trend of the BIIB data is mostly constant during the first third, increasing during the second third, and mostly constant in the last third of the data. We can also see there is seasonality and that the randomness of the data gets larger from approximately 2012 on Based on the QQ plot, the data would be normal if we were to apply a 1^3 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. Finally, with a skewness 0f 14.18 and a kurtosis value of 264.054, we can definitively say the residuals are not normal.

### Partial Model

```{r echo=FALSE}

model=arima(slice1,order=c(0,2,2))

data = read_excel("MadisonPolley1.xlsx", sheet = "BIIB")[-1,]

ts = ts(data$Close[750:1700], frequency = 253, start = c(2008, 12, 24))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```

Here we can see in the Decomposition plot, the trend of the subset of BIIB data is generally increasing. We can also see there is seasonality and that the randomness of the data is fairly large. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. With a skewness 0f -0.56, the data does not seem very skewed. Finally, with the kurtosis value of 5.189, we can definitively say the residuals are not normal.

# Dataset 3: BKNG, 11/6/2009 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.

#BKNG

data = read_excel("MadisonPolley1.xlsx", sheet = "BKNG")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(data_without.last.five,order=c(4,0,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals ,order=c(0,2))
summary(g)
plot(g$residuals)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for BKNG is ARIMA(4,0,3).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.

#BKNG

data = read_excel("MadisonPolley1.xlsx", sheet = "BKNG")[-1,]
plot(data$Close)
plot(data$Close[1:1600])
plot(data$NegLog[1:1600], type = 'o')
slice1 = data[1:1595, 8]
slice1.last5 = data[1596:1600, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

(i). For BKNG, we split the data from 0 to 1600 based on the plot of the "Close" data. The best model for the subset of BKNG is ARIMA(0,1,1).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of BKNG, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 **GARCH** ONLY in this.

model=arima(data_without.last.five,order=c(4,0,3))

#GARCH
g = garch(model$residuals ,order=c(0,2))
summary(g)
plot(g$residuals)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(BKNG). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(0,2) with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 **GARCH** ONLY in this.

model=arima(slice1,order=c(0,0,1))

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this GARCH model  is  the  final  model is because all of the coefficiants are significant and the model had relative convergence. 
We chose this model for this stock as the final model because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf.

## 1.4 Some diagnostic results

### Full Model

```{r echo=FALSE}

model=arima(data_without.last.five,order=c(0,2,2))

data = read_excel("MadisonPolley1.xlsx", sheet = "BKNG")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```

Here we can see in the Decomposition plot, the trend of the BKNG data is generally increasing. We can also see there is seasonality. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. With a skewness value of -0.01, the data does not appear to be skewed, but with a kurtosis value of 9,44, we can definitively say the residuals are not normal.

### Partial Model

```{r echo=FALSE}

model=arima(slice1,order=c(0,1,1))

data = read_excel("MadisonPolley1.xlsx", sheet = "BKNG")[-1,]

ts = ts(data$Close[1:1600], frequency = 253, start = c(2009, 11, 09))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```

Here we can see in the Decomposition plot, the trend of the subset of BKNG data is generally increasing. We can also see there is seasonality and the randomness is quite large. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. With a skewness value of -0.24, the data does not appear to be very skewed, but with a kurtosis value of 11.31, we can definitively say the residuals are not normal.


# Dataset 4: BLK, 4/4/2011 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.

#BLK

data = read_excel("MadisonPolley1.xlsx", sheet = "BLK")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)


#fit ARMA
model=arima(data_without.last.five,order=c(5,2,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals ,order=c(0,2))
summary(g)
plot(g$residuals)

```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for BLK is ARIMA(5,2,1).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.

#BLK

data = read_excel("MadisonPolley1.xlsx", sheet = "BLK")[-1,]
plot(data$Close)
plot(data$Close[500:1600])
plot(data$NegLog[500:1600], type = 'o')
slice1 = data[500:1595, 8]
slice1.last5 = data[1596:1600, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])

```

(i). For BLK, we split the data from 500 to 1600 based on the plot of the "Close" data. The best model for the subset of BLK is ARIMA(0,1,1).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of BLK, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 **GARCH** ONLY in this.

model=arima(data_without.last.five,order=c(5,2,1))

#GARCH
g = garch(model$residuals ,order=c(0,2))
summary(g)
plot(g$residuals)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,2). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(0,1) with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 **GARCH** ONLY in this.

model=arima(slice1,order=c(0,1,1))

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this GARCH model  is  the  final  model is because all of the coefficiants are significant and the model had relative convergence. 
We chose this model for this stock as the final model because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf.

## 1.4 Some diagnostic results

### Full Model

```{r echo=FALSE}
model=arima(data_without.last.five,order=c(0,2,2))


data = read_excel("MadisonPolley1.xlsx", sheet = "BLK")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```

Here we can see in the Decomposition plot, the trend of the BLK data is generally increasing. We can also see there is seasonality. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. With a skewness value of 0.17, the data does not appear to be very skewed, but with a kurtosis value of 8.34, we can definitively say the residuals are not normal.

### Partial Model

```{r echo=FALSE}

model=arima(slice1,order=c(0,1,1))

data = read_excel("MadisonPolley1.xlsx", sheet = "BLK")[-1,]

ts = ts(data$Close[500:1600], frequency = 253, start = c(2013, 04, 02))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```

Here we can see in the Decomposition plot, the trend of the subset of BLK data is generally increasing. We can also see there is seasonality and the randomness is quite variable. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. With a skewness value of 0.32, the data does not appear to be very skewed. With a kurtosis value of 2.09, we conclude the residuals are not too far from normal.


# Dataset 5: CVS, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.

#CVS

data = read_excel("MadisonPolley1.xlsx", sheet = "CVS")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(data_without.last.five,order=c(2,0,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals ,order=c(0,2))
summary(g)
plot(g$residuals)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for CVS is ARIMA(2,0,3).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.

#CVS

data = read_excel("MadisonPolley1.xlsx", sheet = "CVS")[-1,]
plot(data$Close)
plot(data$Close[1200:2000])
plot(data$NegLog[1200:2000], type = 'o')
slice1 = data[1200:1995, 8]
slice1.last5 = data[1996:2000, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

(i). For CVS, we split the data from 1200 to 2000 based on the plot of the "Close" data. The best model for the subset of CVS is ARIMA(0,0,1).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of CVS, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 **GARCH** ONLY in this.

model=arima(data_without.last.five,order=c(2,0,3))

g = garch(model$residuals ,order=c(0,2))
summary(g)
plot(g$residuals)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,2). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(1,1) with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 **GARCH** ONLY in this.

model=arima(slice1,order=c(0,0,1))

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this GARCH model  is  the  final  model is because all of the coefficiants are significant and the model had relative convergence. 
We chose this model for this stock as the final model because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf.

## 1.4 Some diagnostic results

### Full Model

```{r echo=FALSE}
model=arima(data_without.last.five,order=c(0,2,2))


data = read_excel("MadisonPolley1.xlsx", sheet = "CVS")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/3)) 
qqline((model$residuals)^(1/3))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 

Here we can see in the Decomposition plot, the trend of the CVS data is generally increasing until a little after 2015, where it starts to decrease. We can also see there is seasonality and the randomness gradually increases. Based on the QQ plot, the data would be normal if we were to apply a 1^3 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. With a skewness value of -0.72, the data does appears slightly skewed, but with a kurtosis value of 9.44, we can definitively say the residuals are not normal.


### Partial Model

```{r echo=FALSE}

model=arima(slice1,order=c(0,0,1))

data = read_excel("MadisonPolley1.xlsx", sheet = "CVS")[-1,]

ts = ts(data$Close[1200:2000], frequency = 253, start = c(2010, 10, 08))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```

Here we can see in the Decomposition plot, the trend of the subset of CVS data is generally increasing. We can also see there is seasonality and the randomness is quite variable. Based on the QQ plot, the data would be normal if we were to apply a 1^3 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. With a skewness value of 0.12, the data does not appear to be skewed, but with a kurtosis value of 5.25, we can definitively say the residuals are not normal.


# Dataset 6: DHR, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.

#DHR

data = read_excel("MadisonPolley1.xlsx", sheet = "DHR")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(data_without.last.five,order=c(0,0,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals ,order=c(0,1))
summary(g)
plot(g$residuals)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for DHR is ARIMA(0,0,1).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.

#DHR

data = read_excel("MadisonPolley1.xlsx", sheet = "DHR")[-1,]
plot(data$Close)
plot(data$Close[1000:2000])
plot(data$NegLog[1000:2000], type = 'o')
slice1 = data[1000:1995, 8]
slice1.last5 = data[1996:2000, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(1,0,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

(i). For DHR, we split the data from 1000 to 2000 based on the plot of the "Close" data. The best model for the subset of DHR is ARIMA(1,0,1).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of DHR, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 **GARCH** ONLY in this.

model=arima(data_without.last.five,order=c(0,0,1))

#GARCH
g = garch(model$residuals ,order=c(0,1))
summary(g)
plot(g$residuals)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(0,1) with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 **GARCH** ONLY in this.

model=arima(slice1,order=c(1,0,1))

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this GARCH model  is  the  final  model is because all of the coefficiants are significant and the model had relative convergence. 
We chose this model for this stock as the final model because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf.

## 1.4 Some diagnostic results

### Full Model

```{r echo=FALSE}
model=arima(data_without.last.five,order=c(0,2,2))


data = read_excel("MadisonPolley1.xlsx", sheet = "DHR")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```

Here we can see in the Decomposition plot, the trend of the DHR data is generally increasing. We can also see there is seasonality and the randomness increases around 2019. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. With a skewness value of -0.2, the data does not appear to be very skewed, but with a kurtosis value of 5.9, we can definitively say the residuals are not normal.


### Partial Model

```{r echo=FALSE}

model=arima(slice1,order=c(1,0,1))

data = read_excel("MadisonPolley1.xlsx", sheet = "DHR")[-1,]

ts = ts(data$Close[1000:2000], frequency = 253, start = c(2009, 12, 22))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```


Here we can see in the Decomposition plot, the trend of the DHR data is generally increasing. We can also see there is seasonality and the randomness is variable. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. With a skewness value of 0.3, the data does not appear to be very skewed and with a kurtosis value of 2.53, the residuals may be close to normal.


# Dataset 7: EXC, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.

#EXC

data = read_excel("MadisonPolley1.xlsx", sheet = "EXC")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(data_without.last.five,order=c(3,1,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals ,order=c(0,1))
summary(g)
plot(g$residuals)

```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for EXC is ARIMA(3,1,3).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.

#EXC

data = read_excel("MadisonPolley1.xlsx", sheet = "EXC")[-1,]
plot(data$Close)
plot(data$Close[2600:3100])
plot(data$NegLog[2600:3100], type = 'o')
slice1 = data[2600:3095, 8]
slice1.last5 = data[3096:3100, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(2,1,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

(i). For EXC, we split the data from 2600 to 3100 based on the plot of the "Close" data. The best model for the subset of EXC is ARIMA(2,1,3).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of EXC, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 **GARCH** ONLY in this.

model=arima(data_without.last.five,order=c(3,1,3))

#GARCH
g = garch(model$residuals ,order=c(0,1))
summary(g)
plot(g$residuals)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(I0,1) with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 **GARCH** ONLY in this.

model=arima(slice1,order=c(2,1,3))

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this GARCH model  is  the  final  model is because all of the coefficiants are significant and the model had relative convergence. 
We chose this model for this stock as the final model because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf.

## 1.4 Some diagnostic results

### Full Model

```{r echo=FALSE}
model=arima(data_without.last.five,order=c(0,2,2))


data = read_excel("MadisonPolley1.xlsx", sheet = "EXC")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the Decomposition plot, the trend of the EXC data is increasing until approximately 2008, decreasing until about 2016, increasing until 2019, and then decreasing. We can also see there is seasonality and the randomness is most prevalent from 2006 until around 2009. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. With a skewness value of -0.38, the data does not appear to be very skewed, but with a kurtosis value of 15.68, we can definitively say the residuals are not normal.


### Partial Model

```{r echo=FALSE}

model=arima(slice1,order=c(2,1,3))

data = read_excel("MadisonPolley1.xlsx", sheet = "EXC")[-1,]

ts = ts(data$Close[2600:3100], frequency = 200, start = c(2016, 05, 03))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```

Here we can see in the Decomposition plot, the trend of the subset of EXC data is generally increasing. We can also see there is seasonality and the randomness is 0 for the first half of 2017. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. With a skewness value of 0.24, the data does not appear to be very skewed. With a kurtosis value of 2.3, the residuals may be close to normal.

# Dataset 8: GOOG, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.

#GOOG

data = read_excel("MadisonPolley1.xlsx", sheet = "GOOG")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(data_without.last.five,order=c(3,2,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals ,order=c(0,1))
summary(g)
plot(g$residuals)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for GOOG is ARIMA(3,2,0).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.

#GOOG

data = read_excel("MadisonPolley1.xlsx", sheet = "GOOG")[-1,]
plot(data$Close)
plot(data$Close[2800:3500])
plot(data$NegLog[2800:3500], type = 'o')
slice1 = data[2800:3495, 8]
slice1.last5 = data[3496:3500, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

(i). For GOOG, we split the data from 2800 to 3500 based on the plot of the "Close" data. The best model for the subset of GOOG is ARIMA(0,1,1).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of GOOG, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 **GARCH** ONLY in this.

model=arima(data_without.last.five,order=c(3,2,0))

#GARCH
g = garch(model$residuals ,order=c(0,1))
summary(g)
plot(g$residuals)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(0,2) with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 **GARCH** ONLY in this.

model=arima(slice1,order=c(0,1,1))

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this GARCH model  is  the  final  model is because all of the coefficiants are significant and the model had relative convergence. 
We chose this model for this stock as the final model because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf.

## 1.4 Some diagnostic results

### Full Model

```{r echo=FALSE}
model=arima(data_without.last.five,order=c(0,2,2))


data = read_excel("MadisonPolley1.xlsx", sheet = "GOOG")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the Decomposition plot, the trend of the GOOG data is generally increasing. We can also see there is seasonality and the randomness is more prevalend from approximately 2017 through the end of the data. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. With a skewness value of -0.72, the data appears to be slightly skewed, but with a kurtosis value of 9.44, we can definitively say the residuals are not normal.


### Partial Model

```{r echo=FALSE}

model=arima(slice1,order=c(0,1,1))

data = read_excel("MadisonPolley1.xlsx", sheet = "GOOG")[-1,]

ts = ts(data$Close[2800:3500], frequency = 253, start = c(2017, 02, 16))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```

Here we can see in the Decomposition plot, the trend of the subset of GOOG data is generally increasing. We can also see there is seasonality and the randomness is 0 for several straight months in 2018. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. With a skewness value of 0.17, the data does not appear to be very skewed, but with a kurtosis value of 5.48, we can definitively say the residuals are not normal.

# Dataset 9: MA, 5/26/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "MA")[-1,8]

data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

model=arima(data_without.last.five,order=c(2,0,1))
forecast=predict(model,n.ahead=5)$pred
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))
MSFE = sum((fore$forecast-fore$actual)^2)/5

g = garch(model$residuals, order=c(0,1))
x = summary(g)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for MA is ARIMA(2,0,1).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "MA")[-1,]
plot(data$Close)
plot(data$NegLog[0:2500], type = 'o')
slice1 = data[0:2500, 8]
slice1.last5 = data[2501:2505, 8]

model=arima(slice1,order=c(0,0,1))
forecast=predict(model,n.ahead=5)$pred
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))
MSFE = sum((fore$forecast-fore$actual)^2)/5
g = garch(model$residuals, order=c(1,1))
```

(i). For MA, we split the data from 0 to 2500 based on the plot of the "Close" data. The best model for the subset of MA is ARIMA(0,0,1).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of MA, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
model=arima(data_without.last.five,order=c(2,0,1))
g = garch(model$residuals, order=c(0,1))
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(1,1) with the following estimated parameter values and standard errors.
```{r include=FALSE}
model=arima(slice1,order=c(0,0,1))
g = garch(model$residuals, order=c(1,1))
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The reason why we chose this model for this stock as the final model is because a higher p value gives NaN coefficients and a higher q value gives higher p-values.

## 1.4 Some diagnostic results

### Full Model
The left panel is the residual QQ plot.  The right panel is the squared residual ACF plot.
```{r echo=FALSE}
model=arima(data_without.last.five,order=c(2,0,1))
shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(model$residuals))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))

data = read_excel("MadisonPolley1.xlsx", sheet = "MA")
ts = ts(data$Close, frequency = 253, start = c(2006, 1,3))
plot(decompose(ts))
```
As seen from the decomposed data, there is a clear seasonality trend in the Close data. The skewness for this data is -0.2966821, which shows rough normality, and the kurtosis value is 8.708883. We can also see that by transforming the data using the 4th root, the normal Q-Q plot resembles normal data. Therefore, by transforming the residuals we would be able to see a change in the p-values of the Shapiro and Jarque Bera tests.

### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(0,0,1))

data = read_excel("MadisonPolley1.xlsx", sheet = "MA")[-1,]

ts = ts(data$Close[1:2500], frequency = 253, start = c(2006, 5, 30))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```


Here we can see in the subset Decomposition plot, the trend of the MA data is generally increasing with some seasonality. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. Finally, with a skewness of -0.4203304 and a kurtosis value of 7.697419, we can definitively say the residuals are not normal.

# Dataset 10: MDLZ, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "MDLZ")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(2,1,4))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for MDLZ is ARIMA(2,1,4).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "MDLZ")[-1,]
plot(data$Close)
plot(data$NegLog[2600:3200], type = 'o')
slice1 = data[2600:3200, 8]
slice1.last5 = data[3201:3205, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(1,1,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
```

(i). For MDLZ, we split the data from 2600 to 3200 based on the plot of the "Close" data. The best model for the subset of MDLZ is ARIMA(1,1,2).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of MDLZ, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
model=arima(data_without.last.five,order=c(2,1,4))
g = garch(model$residuals, order=c(0,1))
summary(g)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(1,1) with the following estimated parameter values and standard errors.
```{r include=FALSE}
model=arima(slice1,order=c(1,1,2))
g = garch(model$residuals, order=c(1,1))
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The reason why we chose this model for this stock as the final model is because any higher value of p or q gives NaN values or less significant coefficients than this model.

## 1.4 Some diagnostic results
### Full Model
The left panel is the residual QQ plot.  The right panel is the squared residualACF plot.
```{r echo=FALSE}
model=arima(data_without.last.five,order=c(2,1,4))
shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(model$residuals))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))

data = read_excel("MadisonPolley1.xlsx", sheet = "MDLZ")
ts = ts(data$Close, frequency = 253, start = c(2006, 1,3))
plot(decompose(ts))
```
As seen from the decomposed data, there is a clear seasonality trend in the Close data. The skewness for this data is 5.47866, which shows rough normality, and the kurtosis value is 150.2846. We can also see that by transforming the data using the 4th root, the normal Q-Q plot resembles normal data. Therefore, by transforming the residuals we would be able to see a change in the p-values of the Shapiro and Jarque Bera tests.


### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(1,1,2))

data = read_excel("MadisonPolley1.xlsx", sheet = "MDLZ")[-1,]

ts = ts(data$Close[2600:3200], frequency = 253, start = c(2009, 7, 31))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```


Here we can see in the subset Decomposition plot, the trend of the MDLZ data is generally increasing with some seasonality. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. Finally, with a skewness of -0.002844687 and a kurtosis value of 3.889932, we can definitively say the residuals are not normal.

# Dataset 11: MO, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
#MO
data = read_excel("MadisonPolley1.xlsx", sheet = "MO")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,1,1))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for MO is ARIMA(0,1,1).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "MO")[-1,]
plot(data$Close)
plot(data$NegLog[900:2500], type = 'o')
slice1 = data[900:2500, 8]
slice1.last5 = data[2501:2505, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

(i). For MO, we split the data from 900 to 2500 based on the plot of the "Close" data. The best model for the subset of MO is ARIMA(0,1,1).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of MO, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
model=arima(data_without.last.five,order=c(0,1,1))
g = garch(model$residuals, order=c(0,1))
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(0,2) with the following estimated parameter values and standard errors.
```{r include=FALSE}
model=arima(slice1,order=c(0,1,1))
g = garch(model$residuals, order=c(0,2))
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The reason why we chose this model for this stock as the final model is because it provided the highest q value with the most significant coefficient values.

## 1.4 Some diagnostic results
### Full Model
The left panel is the residual QQ plot.  The right panel is the squared residualACF plot.
```{r echo=FALSE}
model=arima(data_without.last.five,order=c(0,1,1))
shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(model$residuals))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))

data = read_excel("MadisonPolley1.xlsx", sheet = "MO")
ts = ts(data$Close, frequency = 253, start = c(2006, 1,3))
plot(decompose(ts))
```
As seen from the decomposed data, there is a clear seasonality trend in the Close data. The skewness for this data is 32.87243, which shows rough normality, and the kurtosis value is 1612.556. We can also see that by transforming the data using the 4th root, the normal Q-Q plot resembles normal data. Therefore, by transforming the residuals we would be able to see a change in the p-values of the Shapiro and Jarque Bera tests.


### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(0,1,1))

data = read_excel("MadisonPolley1.xlsx", sheet = "MO")[-1,]

ts = ts(data$Close[900:2500], frequency = 253, start = c(2009, 7, 31))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```


Here we can see in the subset Decomposition plot, the trend of the MO data is generally increasing with some seasonality. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. Finally, with a skewness of 0.3985076 and a kurtosis value of 2.035654, we can definitively say the residuals are not normal.

# Dataset 12: SBUX, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "SBUX")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,1,2))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for SBUX is ARIMA(0,1,2).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "SBUX")[-1,]
plot(data$Close)
plot(data$NegLog[900:2400], type = 'o')
slice1 = data[900:2400, 8]
slice1.last5 = data[2401:2405, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(2,1,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

(i). For SBUX, we split the data from 900 to 2400 based on the plot of the "Close" data. The best model for the subset of SBUX is ARIMA(2,1,3).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of SBUX, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
model=arima(data_without.last.five,order=c(0,1,2))
g = garch(model$residuals, order=c(0,1))
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(0,2) with the following estimated parameter values and standard errors.
```{r include=FALSE}
model=arima(slice1,order=c(2,1,3))
g = garch(model$residuals, order=c(0,2))
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The reason why we chose this model for this stock as the final model is because the p-values were the best with this model.

## 1.4 Some diagnostic results
### Full Model
The left panel is the residual QQ plot.  The right panel is the squared residualACF plot.
```{r echo=FALSE}
model=arima(data_without.last.five,order=c(0,1,2))
shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(model$residuals))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))

data = read_excel("MadisonPolley1.xlsx", sheet = "MA")
ts = ts(data$Close, frequency = 253, start = c(2006, 1,3))
plot(decompose(ts))
```
As seen from the decomposed data, there is a clear seasonality trend in the Close data. The skewness for this data is -0.2966821, which shows rough normality, and the kurtosis value is 8.708883. We can also see that by transforming the data using the 4th root, the normal Q-Q plot resembles normal data. Therefore, by transforming the residuals we would be able to see a change in the p-values of the Shapiro and Jarque Bera tests.


### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(2,1,3))

data = read_excel("MadisonPolley1.xlsx", sheet = "SBUX")[-1,]
data$Date[900]
ts = ts(data$Close[900:2400], frequency = 253, start = c(2009, 7, 31))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```


Here we can see in the subset Decomposition plot, the trend of the SBUX data is generally increasing with some seasonality. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. Finally, with a skewness of -0.08715143 and a kurtosis value of 4.626367, we can definitively say the residuals are not normal.


# Dataset 13: ZION, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
#ZION
data = read_excel("MadisonPolley1.xlsx", sheet = "ZION")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(2,2,4))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for ZION is ARIMA(2,2,4).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "ZION")[-1,]
plot(data$Close)
plot(data$NegLog[2500:3000], type = 'o')
slice1 = data[2500:3000, 8]
slice1.last5 = data[3001:3005, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
```

(i). For ZION, we split the data from 2500 to 3000 based on the plot of the "Close" data. The best model for the subset of ZION is ARIMA(0,2,2).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of ZION, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
model=arima(slice1,order=c(2,1,3))
g = garch(model$residuals, order=c(0,1))
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(1,1) with the following estimated parameter values and standard errors.
```{r include=FALSE}
model=arima(slice1,order=c(0,2,2))
g = garch(model$residuals, order=c(1,1))
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```


The reason why we chose this model for this stock as the final model because it gives the lowest p-values with the highest p and q values.

## 1.4 Some diagnostic results
### Full Model
The left panel is the residual QQ plot.  The right panel is the squared residualACF plot.
```{r echo=FALSE}
model=arima(data_without.last.five,order=c(0,1,2))
shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(model$residuals))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))

data = read_excel("MadisonPolley1.xlsx", sheet = "SBUX")
ts = ts(data$Close, frequency = 253, start = c(2006, 1,3))
plot(decompose(ts))
```
As seen from the decomposed data, there is a clear seasonality trend in the Close data. The skewness for this data is -0.2127466, which shows rough normality, and the kurtosis value is 13.56661. We can also see that by transforming the data using the 4th root, the normal Q-Q plot resembles normal data. Therefore, by transforming the residuals we would be able to see a change in the p-values of the Shapiro and Jarque Bera tests.

### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(0,2,2))

data = read_excel("MadisonPolley1.xlsx", sheet = "ZION")[-1,]

ts = ts(data$Close[2500:3000], frequency = 12, start = c(2015, 12, 8))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```


Here we can see in the subset Decomposition plot, the trend of the ZION data is generally increasing with some seasonality. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. Finally, with a skewness 0f 0.3911495 and a kurtosis value of 3.528505, we can definitively say the residuals are not normal.


# Dataset 14: VMC, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
#VMC
data = read_excel("MadisonPolley1.xlsx", sheet = "VMC")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,2,4))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for VMC is ARIMA(1,2,4).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "VMC")[-1,]
plot(data$Close)
plot(data$NegLog[1500:2600], type = 'o')
slice1 = data[1500:2600, 8]
slice1.last5 = data[2601:2605, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
```

(i). For VMC, we split the data from 1500 to 2600 based on the plot of the "Close" data. The best model for the subset of VMC is ARIMA(0,1,1).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of VMC, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#VMC
data = read_excel("MadisonPolley1.xlsx", sheet = "VMC")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,2,4))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,2). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(1,2) with the following estimated parameter values and standard errors.
```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "VMC")[-1,]

#fit ARMA
model=arima(slice1,order=c(0,1,1))

#GARCH
g = garch(model$residuals, order=c(1,2))
summary(g)
plot(g$residuals)
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The reason why we chose this model for this stock as the final model is because all the coefficients were significant and the acf and pacf plots matched the theoretical plots. Therefore this model also had the lowest error.

## 1.4 Some diagnostic results
### Full Model

The left panel is the residual QQ plot.  The right panel is the squared residual ACF plot.
```{r echo=FALSE}
model=arima(data_without.last.five,order=c(1,2,4))
shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(model$residuals))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))

data = read_excel("MadisonPolley1.xlsx", sheet = "VMC")
ts = ts(data$Close, frequency = 253, start = c(2006, 1,3))
plot(decompose(ts))
```
As seen from the decomposed data, there is a clear seasonality trend in the Close data. The skewness for this data is -0.325688, which shows rough normality, and the kurtosis value is 6.320678. We can also see that by transforming the data using the 4th root, the normal Q-Q plot resembles normal data. Therefore, by transforming the residuals we would be able to see a change in the p-values of the Shapiro and Jarque Bera tests.



### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(0,1,1))

data = read_excel("MadisonPolley1.xlsx", sheet = "VMC")[-1,]

ts = ts(data$Close[1500:2600], frequency = 253, start = c(2011, 12, 15))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```


Here we can see in the subset Decomposition plot, the trend of the VMC data is generally increasing with some seasonality. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. Finally, with a skewness of -0.1257718 and a kurtosis value of 3.559519, we can definitively say the residuals are not normal.


# Dataset 15: VLO, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
#VLO
data = read_excel("MadisonPolley1.xlsx", sheet = "VLO")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(16,1,0))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)

```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for VLO is ARIMA(16,1,0).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "VLO")[-1,]
plot(data$Close)
plot(data$NegLog[1000:2300], type = 'o')
slice1 = data[1000:2300, 8]
slice1.last5 = data[2301:2305, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,2))
summary(g)
plot(g$residuals)

```

(i). For VLO, we split the data from 1000 to 2300 based on the plot of the "Close" data. The best model for the subset of VLO is ARIMA(0,1,1).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of VLO, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "VLO")[-1,8]

model=arima(data_without.last.five,order=c(16,1,0))

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(1,2) with the following estimated parameter values and standard errors.
```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "VLO")[-1,]

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#GARCH
g = garch(model$residuals, order=c(1,2))
summary(g)
plot(g$residuals)

```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this  model  is  the  final  model,  instead  of  GARCH(1,2),GARCH(2,1), or GARCH(2,2) is because the p-values are very small for each coefficient, and the error was as small as possible.

## 1.4 Some diagnostic results

### Full Model
The left panel is the residual QQ plot.  The right panel is the squared residualACF plot.
```{r echo=FALSE}
model=arima(data_without.last.five,order=c(16,1,0))
shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(model$residuals))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))

data = read_excel("MadisonPolley1.xlsx", sheet = "VLO")
ts = ts(data$Close, frequency = 253, start = c(2006, 1,3))
plot(decompose(ts))
```
As seen from the decomposed data, there is a clear seasonality trend in the Close data. The skewness for this data is -0.126578, which shows rough normality, and the kurtosis value is 9.232833. We can also see that by transforming the data using the 4th root, the normal Q-Q plot resembles normal data. Therefore, by transforming the residuals we would be able to see a change in the p-values of the Shapiro and Jarque Bera tests.



### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(0,1,1))

data = read_excel("MadisonPolley1.xlsx", sheet = "VLO")[-1,]

ts = ts(data$Close[1000:2300], frequency = 253, start = c(2009, 12, 22))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```


Here we can see in the subset Decomposition plot, the trend of the VLO data is generally increasing with some seasonality. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. Finally, with a skewness 0f 0.01899778 and a kurtosis value of 3.059231, we can definitively say the residuals are not normal.


# Dataset 16: TSN, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
#TSN
data = read_excel("MadisonPolley1.xlsx", sheet = "TSN")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,2,2))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)

```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for TSN is ARIMA(0,2,2).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "TSN")[-1,]
plot(data$Close)
plot(data$NegLog[800:2500], type = 'o')
slice1 = data[800:2500, 8]
slice1.last5 = data[2501:2505, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(1,1,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
sum(model$residuals)^(2)
```

(i). For TSN, we split the data from 800 to 2500 based on the plot of the "Close" data. The best model for the subset of TSN is ARIMA(1,1,2).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of TSN, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
model=arima(data_without.last.five,order=c(0,2,2))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)

```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,2). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(0,2) with the following estimated parameter values and standard errors.
```{r include=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "TSN")[-1,]
plot(data$Close)
plot(data$NegLog[800:2500], type = 'o')
slice1 = data[800:2500, 8]
slice1.last5 = data[2501:2505, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(1,1,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
sum(model$residuals)^(2)

```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The reason why we chose this model for this stock as the final model is because the sum of the squared residuals is fairly low, and the coefficients are all significant with a GARCH(0,2).

## 1.4 Some diagnostic results

### Full Model
The left panel is the residual QQ plot.  The right panel is the squared residualACF plot.
```{r echo=FALSE}
model=arima(data_without.last.five,order=c(0,2,2))
shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(model$residuals))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))

data = read_excel("MadisonPolley1.xlsx", sheet = "TSN")
ts = ts(data$Close, frequency = 253, start = c(2006, 1,3))
plot(decompose(ts))
```
As seen from the decomposed data, there is a clear seasonality trend in the Close data with an upward trend. The skewness for this data is 0.3098, which shows rough normality, and the kurtosis value is 14.49. We can also see that by transforming the data using the 4th root, the normal Q-Q plot resembles normal data. Therefore, by transforming the residuals we would be able to see a change in the p-values of the Shapiro and Jarque Bera tests.

### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(1,1,0))

data = read_excel("MadisonPolley1.xlsx", sheet = "TSN")[-1,]

ts = ts(data$Close[800:2500], frequency = 253, start = c(2009, 3, 10))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```


Here we can see in the subset Decomposition plot, the trend of the TSN data is generally increasing with some seasonality. Based on the QQ plot, the data would be normal if we were to apply a 1^4 transformation to the response varibale of our model; however, the transformation dramatically increased our msfe, so we decided not to apply it. The Shapiro-Wilk test and the Jarque Bera test show that the model's residuals are not normally distributed without the transformation. Finally, with a skewness 0f 0.07107268 and a kurtosis value of 2.946439, we can definitively say the residuals are not normal.











# Dataset 17: SNA, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
#SNA
#Part 1

data = read_excel("MadisonPolley1.xlsx", sheet = "SNA")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,0,0))
coeftest(model)
model
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,2))
summary(g)
plot(g$residuals)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for SNA is ARIMA(0,0,0).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.
data = read_excel("MadisonPolley1.xlsx", sheet = "SNA")[-1,]
plot(data$Close)
plot(data$NegLog[1400:2400], type = 'o')
slice1 = data[1400:2400, 8]
slice1.last5 = data[2401:2405, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

(i). For SNA, we split the data from 1400 to 2400 based on the plot of the "Close" data. The best model for the subset of SNA is ARIMA(0,0,0).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of SNA, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 ONLY in this.
#SNA
#Part 1

data = read_excel("MadisonPolley1.xlsx", sheet = "SNA")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,0,0))
coeftest(model)
model
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,2))
summary(g)
plot(g$residuals)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(1,2). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```


## 1.3 The best fitted model is  GARCH(0,2)  with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this.
data = read_excel("MadisonPolley1.xlsx", sheet = "SNA")[-1,]
plot(data$Close)
plot(data$NegLog[1400:2400], type = 'o')
slice1 = data[1400:2400, 8]
slice1.last5 = data[2401:2405, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this  model  is  the  final  model,  instead  of  GARCH(1,2),GARCH(2,1), or GARCH(2,2): is because all p-values for the coefficients are significant and this model had a high p-value in the box-ljung test. 
The reason why we chose this ARIMA model for this stock as the final model is because we had significant coefficients, a low msfe value and the acf and pacf cloesly resembled the predicted acf and pacf. 

## 1.4 Some diagnostic results
### Full Model

```{r echo=FALSE}

data = read_excel("MadisonPolley1.xlsx", sheet = "SNA")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(data$Close, type = "l")
plot(decompose(ts))

model=arima(data_without.last.five,order=c(0,0,0))

shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of SNA, that the trend of the SNA data is increasing after 2010 and there is a clear seasonality.

Based on the QQ plot, the data would be normal if we applied a ^(1/6) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is not zero, indicating skewness in data. Our kurtosis value is not zero. Hence our SNA is data is not normal. 

### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(0,0,0))

data = read_excel("MadisonPolley1.xlsx", sheet = "SNA")[-1,]
ts = ts(data$Close[1400:2400], frequency = 253, start = c(2011, 07, 27))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of SNA, that the trend of the SNA data is constantly increasing after 2011 and there is a clear seasonality.

Based on the QQ plot, the data would be normal if we applied a ^(1/4) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is close to zero, indicating almost no skewness in data. Our kurtosis value is close to zero. 

# Dataset 18: NCLH, 1/22/2013 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.
#NCLH

data = read_excel("MadisonPolley1.xlsx", sheet = "NCLH")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,1,1))
coeftest(model)
model
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)

```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for ---NCLH--- is ARIMA(1,1,1).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.
data = read_excel("MadisonPolley1.xlsx", sheet = "NCLH")[-1,]
plot(data$Close)
plot(data$NegLog[450:1000], type = 'o')
slice1 = data[450:1000, 8]
slice1.last5 = data[1001:1005, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
```

(i). For ---NCLH---, we split the data from 450 to 10000  based on the plot of the "Close" data. The best model for the subset of NCLH is ARIMA(0,0,0).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of NCLH, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#NCLH

data = read_excel("MadisonPolley1.xlsx", sheet = "NCLH")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,1,1))
coeftest(model)
model
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)

```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(1,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is  GARCH(0,1)  with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this.
data = read_excel("MadisonPolley1.xlsx", sheet = "NCLH")[-1,]
plot(data$Close)
plot(data$NegLog[450:1000], type = 'o')
slice1 = data[450:1000, 8]
slice1.last5 = data[1001:1005, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this  model  is  the  final  model,  instead  of  GARCH(1,2),GARCH(2,1), or GARCH(2,2): is because all p-values for the coefficients are significant and this model had a high p-value in the box-ljung test. 
The reason why we chose the ARIMA model for this stock as the final model is because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf. 

## 1.4 Some diagnostic results
### Full Model
The left panel is the residual QQ plot.  The right panel is the squared residualACF plot.
```{r echo=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "NCLH")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2013,1,3))
plot(data$Close, type = "l")
plot(decompose(ts))

model=arima(data_without.last.five,order=c(1,1,1))
shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 

Here we can see in the decomposition plot of NCLH, that the trend of the NCLH data is increasing after 2014 and dips in 2018 and goes back up, and dropping again in 2019 showing no clear trend . There is some sort of seasonality pattern.

Based on the QQ plot, the data would be normal if we applied a ^(1/4) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is not zero, indicating skewness in data. Our kurtosis value is not zero. Hence our NCLH is data is not normal.

### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(0,0,0))

data = read_excel("MadisonPolley1.xlsx", sheet = "NCLH")[-1,]

ts = ts(data$Close[450:1000], frequency = 253, start = c(2014, 11, 03))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of NCLH, that the trend of the NCLH data is constantly decreasing after 2014 and there is no clear seasonilty. 

Based on the QQ plot, the data would be normal if we applied a ^(1/4) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is not to zero, indicating almost skewness in data. Our kurtosis value is close to zero.

# Dataset 19: MAA, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.
#MAA
data = read_excel("MadisonPolley1.xlsx", sheet = "MAA")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)

```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for MAA is ARIMA(0,2,2).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.
data = read_excel("MadisonPolley1.xlsx", sheet = "MAA")[-1,]
plot(data$Close)
plot(data$NegLog[1000:2800], type = 'o')
slice1 = data[1000:2800, 8]
slice1.last5 = data[2801:2805, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
model
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

(i). For MAA, we split the data from 1000 to 2800 based on the plot of the "Close" data. The best model for the subset of MAA is ARIMA(0,0,0).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of MAA, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 ONLY in this.
#MAA
data = read_excel("MadisonPolley1.xlsx", sheet = "MAA")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)

```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(0,2) with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this.
data = read_excel("MadisonPolley1.xlsx", sheet = "MAA")[-1,]
plot(data$Close)
plot(data$NegLog[1000:2800], type = 'o')
slice1 = data[1000:2800, 8]
slice1.last5 = data[2801:2805, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
model
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this  model  is  the  final  model,  instead  of  GARCH(1,2),GARCH(2,1), or GARCH(2,2): is because all p-values for the coefficients are significant and this model had a high p-value in the box-ljung test. 
The reason why we chose the ARIMA model for this stock as the final model is because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf. 


## 1.4 Some diagnostic results
### Full Model
The left panel is the residual QQ plot.  The right panel is the squared residualACF plot.
```{r echo=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "MAA")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(data$Close, type = "l")
plot(decompose(ts))

shapiro.test(na.omit(residuals(model)))
model=arima(data_without.last.five,order=c(0,2,2))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of MAA, that the trend of the MAA data is increasing after 2009 and there is a clear seasonality.

Based on the QQ plot, the data would be normal if we applied a ^(1/4) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is not zero, indicating skewness in data. However the skewness value is very close to zero.  Our kurtosis value is not zero. Hence our MAA  data is not normal.

### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(0,0,0))

data = read_excel("MadisonPolley1.xlsx", sheet = "MAA")[-1,]
ts = ts(data$Close[1000:2800], frequency = 253, start = c(2009, 12, 22))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of MAA, that the trend of the MAA data is constantly increasing after 2009 and there is some sort of seasonilty. 

Based on the QQ plot, the data would be normal if we applied a ^(1/4) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is not to zero, indicating skewness in data. Our kurtosis value is close to zero.                             -

# Dataset 20: MDT, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.
#MDT
data = read_excel("MadisonPolley1.xlsx", sheet = "MDT")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,2,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,2))
summary(g)
plot(g$residuals)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for MDT is ARIMA(0,2,3).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.
data = read_excel("MadisonPolley1.xlsx", sheet = "MDT")[-1,]
plot(data$Close)
plot(data$NegLog[1000:3000], type = 'o')
slice1 = data[1000:3000, 8]
slice1.last5 = data[3001:3005, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
```

(i). For MDT, we split the data from 1000 to 3000 based on the plot of the "Close" data. The best model for the subset of MDT is ARIMA(0,0,0).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of MDT, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 ONLY in this.
#MDT
data = read_excel("MadisonPolley1.xlsx", sheet = "MDT")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,2,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,2))
summary(g)
plot(g$residuals)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(1,2). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is  GARCH(1,2)  with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this.
data = read_excel("MadisonPolley1.xlsx", sheet = "MDT")[-1,]
plot(data$Close)
plot(data$NegLog[1000:3000], type = 'o')
slice1 = data[1000:3000, 8]
slice1.last5 = data[3001:3005, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this  model  is  the  final  model,  instead  of  GARCH(1,2),GARCH(2,1), or GARCH(2,2): is because all p-values for the coefficients are significant and this model had a high p-value in the box-ljung test. 
The reason why we chose the ARIMA model for this stock as the final model is because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf. 


## 1.4 Some diagnostic results
### Full Model
The left panel is the residual QQ plot.  The right panel is the squared residualACF plot.
```{r echo=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "MDT")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(data$Close, type = "l")
plot(decompose(ts))

model=arima(data_without.last.five,order=c(0,2,3))
shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of MDT, that the trend of the MDT data is increasing after 2012 and there is a clear seasonality.

Based on the QQ plot, the data would be normal if we applied a ^(1/4) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is not zero, indicating skewness in data. Our kurtosis value is not zero. Hence our MDT is data is not normal.

### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(0,0,0))

data = read_excel("MadisonPolley1.xlsx", sheet = "MDT")[-1,]
ts = ts(data$Close[1000:3000], frequency = 253, start = c(2009, 12, 22))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of MDT, that the trend of the MDT data is constantly increasing after 2011 and there is some sort of seasonilty. 

Based on the QQ plot, the data would be normal if we applied a ^(1/4) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is not to zero, indicating skewness in data. Our kurtosis value is also not zero.                             

# Dataset 21: JNPR, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.
#JNPR
data = read_excel("MadisonPolley1.xlsx", sheet = "JNPR")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(3,1,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for JNPR is ARIMA(3,1,3).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.
data = read_excel("MadisonPolley1.xlsx", sheet = "JNPR")[-1,]
plot(data$Close)
plot(data$NegLog[1500:3500], type = 'o')
slice1 = data[1500:3500, 8]
slice1.last5 = data[3501:3505, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

(i). For JNPR, we split the data from 1500 to 3500 based on the plot of the "Close" data. The best model for the subset of JNPR is ARIMA(0,1,1).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of JNPR, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 ONLY in this.
#JNPR
data = read_excel("MadisonPolley1.xlsx", sheet = "JNPR")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(3,1,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(1,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is GARCH(0,2) with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this.
data = read_excel("MadisonPolley1.xlsx", sheet = "JNPR")[-1,]
plot(data$Close)
plot(data$NegLog[1500:3500], type = 'o')
slice1 = data[1500:3500, 8]
slice1.last5 = data[3501:3505, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this  model  is  the  final  model,  instead  of  GARCH(1,2),GARCH(2,1), or GARCH(2,2): is because all p-values for the coefficients are significant and this model had a high p-value in the box-ljung test. 
The reason why we chose the ARIMA model for this stock as the final model is because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf. 


## 1.4 Some diagnostic results
### Full Model
The left panel is the residual QQ plot.  The right panel is the squared residualACF plot.
```{r echo=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "JNPR")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(data$Close, type = "l")
plot(decompose(ts))

model=arima(data_without.last.five,order=c(3,1,3))
shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of JNPR, that the trend of the JNPR data is increasing after 2013 and there is a clear seasonality.

Based on the QQ plot, the data would be normal if we applied a ^(1/4) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is not zero, indicating skewness in data. Our kurtosis value is not zero. Hence our JNPR is data is not normal.

### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(0,1,1))

data = read_excel("MadisonPolley1.xlsx", sheet = "JNPR")[-1,]
ts = ts(data$Close[1500:3500], frequency = 253, start = c(2007, 10, 17))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of JNPR, that the trend of the JNPR data is constantly increasing after 2008 and there is some sort of seasonilty. 

Based on the QQ plot, the data would be normal if we applied a ^(1/4) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is not to zero, indicating skewness in data. Our kurtosis value is also not zero. 


# Dataset 22: FE, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.
data = read_excel("MadisonPolley1.xlsx", sheet = "FE")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for FE is ARIMA(1,2,2).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.
data = read_excel("MadisonPolley1.xlsx", sheet = "FE")[-1,]
plot(data$Close)
plot(data$NegLog[500:3000], type = 'o')
slice1 = data[500:3000, 8]
slice1.last5 = data[3001:3005, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

(i). For FE, we split the data from 500 to 3000 based on the plot of the "Close" data. The best model for the subset of FE is ARIMA(0,0,0).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of FE, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 ONLY in this.
data = read_excel("MadisonPolley1.xlsx", sheet = "FE")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(0,2). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is  GARCH(0,2)  with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this.
data = read_excel("MadisonPolley1.xlsx", sheet = "FE")[-1,]
plot(data$Close)
plot(data$NegLog[500:3000], type = 'o')
slice1 = data[500:3000, 8]
slice1.last5 = data[3001:3005, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this  model  is  the  final  model,  instead  of  GARCH(1,2),GARCH(2,1), or GARCH(2,2): is because all p-values for the coefficients are significant and this model had a high p-value in the box-ljung test. 
The reason why we chose the ARIMA model for this stock as the final model is because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf. 


## 1.4 Some diagnostic results
### Full Model
The left panel is the residual QQ plot.  The right panel is the squared residualACF plot.
```{r echo=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "FE")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(data$Close, type = "l")
plot(decompose(ts))

model=arima(data_without.last.five,order=c(1,2,2))
shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of FE, that the trend of the FE data is decreasing after 2008 and there is a clear seasonality.

Based on the QQ plot, the data would be normal if we applied a ^(1/6) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is not zero, indicating skewness in data. Our kurtosis value is not zero. Hence our FE is data is not normal.

### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(0,0,0))

data = read_excel("MadisonPolley1.xlsx", sheet = "FE")[-1,]
ts = ts(data$Close[500:3000], frequency = 253, start = c(2007, 12, 28))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of FE, that the trend of the FE data is constantly decreasing after 2008 and there is some sort of seasonilty. 

Based on the QQ plot, the data would be normal if we applied a ^(1/4) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is close to zero, indicating almost no skewness in  the data. Our kurtosis value is also not zero. 

                             

# Dataset 23: EA, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.
#EA
data = read_excel("MadisonPolley1.xlsx", sheet = "EA")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,0,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)

```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for -EA is ARIMA(1,0,1).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.
data = read_excel("MadisonPolley1.xlsx", sheet = "EA")[-1,]
plot(data$Close)
plot(data$NegLog[1700:3747], type = 'o')
slice1 = data[1700:3747, 8]
slice1.last5 = data[3748:3752, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
```

(i). For EA, we split the data from 1700 to 3747 based on the plot of the "Close" data. The best model for the subset of EA is ARIMA(0,0,1).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of EA, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 ONLY in this.
#EA
data = read_excel("MadisonPolley1.xlsx", sheet = "EA")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,0,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)

```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(1,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is  GARCH(1,1)  with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this.
data = read_excel("MadisonPolley1.xlsx", sheet = "EA")[-1,]
plot(data$Close)
plot(data$NegLog[1700:3747], type = 'o')
slice1 = data[1700:3747, 8]
slice1.last5 = data[3748:3752, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this  model  is  the  final  model,  instead  of  GARCH(1,2),GARCH(2,1), or GARCH(2,2): is because all p-values for the coefficients are significant and this model had a high p-value in the box-ljung test. 
The reason why we chose the ARIMA model for this stock as the final model is because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf. 

## 1.4 Some diagnostic results
### Full Model
The left panel is the residual QQ plot.  The right panel is the squared residualACF plot.
```{r echo=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "EA")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(data$Close, type = "l")
plot(decompose(ts))

model=arima(data_without.last.five,order=c(1,0,1))
shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of EA, that the trend of the EA data is increasing after 2013 and there is a clear seasonality.

Based on the QQ plot, the data would be normal if we applied a ^(1/4) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is not zero, indicating skewness in data. Our kurtosis value is not zero. Hence our EA data is not normal.


### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(0,0,1))

data = read_excel("MadisonPolley1.xlsx", sheet = "EA")[-1,]
ts = ts(data$Close[1700:3747], frequency = 253, start = c(2012, 10, 02))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of FE, that the trend of the FE data is constantly increasing after 2012 and there is some sort of seasonalilty. 

Based on the QQ plot, the data would be normal if we applied a ^(1/4) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is close to zero, indicating almost no skewness in  the data. Our kurtosis value is also not zero. 
                             
# Dataset 24: DLTR, 1/3/2006 - 11/27/2020
## 1.1 ARIMA
```{r include=FALSE}
# Run all R code for PART 1 ONLY in this. output will not be printed, but the following code will be based on this dataset.
#DLTR
data = read_excel("MadisonPolley1.xlsx", sheet = "DLTR")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)

```

1. Fitting the whole dataset (excluding the last 5 values). 

The best model for DLTR is ARIMA(1,2,2).
(i).
```{r echo=FALSE}
coeftest(model)
```

(ii).
The last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown. 
```{r echo=FALSE}
fore
```

(iii).
The mean square forecast error value we obtained from this stock is:
```{r echo=FALSE}
MSFE
```

2. Reports where we split the model as well as fitting the chosen dataset (excluding the last 5 day values)
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this. output will not be printed, but the following code will be based on this dataset.
data = read_excel("MadisonPolley1.xlsx", sheet = "DLTR")[-1,]
plot(data$Close)
plot(data$NegLog[0:1500], type = 'o')
slice1 = data[0:1500, 8]
slice1.last5 = data[1501:1505, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

(i). For DLTR, we split the data from 0 to 1500 based on the plot of the "Close" data. The best model for the subset of DLTR is ARIMA(0,0,2).
```{r echo=FALSE}
coeftest(model)
```

(ii). For the subset of DLTR, the last five data set values are titled 'Actual'. The predicted forecast of the last five data set values are titled 'Forecast', and lastly the forecast errors are titled 'Error' in the table shown.
```{r echo=FALSE}
fore
```

(iii). The mean square forecast error value we obtained for the subset of this stock is:
```{r echo=FALSE}
MSFE
```

## 1.2 GARCH
1. Fitting the residuals from the best ARIMA model whole data set (exclude the last5 day values) and report your best model.

```{r include=FALSE}
#Run all R code for PART 1 ONLY in this.
#DLTR
data = read_excel("MadisonPolley1.xlsx", sheet = "DLTR")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)

```

Our best fitted residuals model from the ARIMA model previously shown is GARCH(1,1). All the p-values are significant. This model also has relative function convergence.
```{r echo=FALSE}
x = summary(g)
x$coef
```

2. The left panel is the log return original series. The right panel is the fitted residuals.
```{r echo=FALSE}
par(mfrow = c(1,2))
plot(data$NegLog, type = "h", ylab = "Index Return", xlab = "Time: daily")
plot(model$residuals, type = "h", ylab = "Standardized Residuals", xlab = "Index")
```

## 1.3 The best fitted model is  GARCH(0,2)  with the following estimated parameter values and standard errors.
```{r include=FALSE}
#Run all R code for PART 2 ONLY in this.
data = read_excel("MadisonPolley1.xlsx", sheet = "DLTR")[-1,]
plot(data$Close)
plot(data$NegLog[0:1500], type = 'o')
slice1 = data[0:1500, 8]
slice1.last5 = data[1501:1505, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

```{r echo=FALSE}
x = summary(g)
x$coef
```

The sum of the squared error of the final model is:
```{r}
(sum(model$residuals))^2
```

The  reason  why  this  model  is  the  final  model,  instead  of  GARCH(1,2),GARCH(2,1), or GARCH(2,2): is because all p-values for the coefficients are significant and this model had a high p-value in the box-ljung test. 
The reason why we chose the ARIMA model for this stock as the final model is because we had significant coefficients, a low msfe value and the acf and pacf closely resembled the predicted acf and pacf. 

## 1.4 Some diagnostic results
### Full Model
The left panel is the residual QQ plot.  The right panel is the squared residualACF plot.
```{r echo=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "DLTR")[-1,]
ts = ts(data$Close, frequency = 253, start = c(2006,1,3))
plot(data$Close, type = "l")
plot(decompose(ts))

model=arima(data_without.last.five,order=c(1,2,2))
shapiro.test(na.omit(residuals(model)))

par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))
acf(model$residuals)

jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of DLTR, that the trend of the DLTR data is increasing after 2006 and there is a clear seasonality.

Based on the QQ plot, the data would be normal if we applied a ^(1/4) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is not zero, indicating skewness in data. Our kurtosis value is not zero. Hence our DLTR data is not normal.

### Partial Model

```{r echo=FALSE}
model=arima(slice1,order=c(0,0,2))

data = read_excel("MadisonPolley1.xlsx", sheet = "DLTR")[-1,]
data$Date[0]
ts = ts(data$Close[0:1500], frequency = 253, start = c(2012, 10, 02))
plot(decompose(ts))
par(mfrow = c(1,2))
# TRANSFORM THE DATA as best as possible to make it normal
qqnorm((model$residuals)^(1/4)) 
qqline((model$residuals)^(1/4))


acf(model$residuals)
shapiro.test(na.omit(residuals(model)))
jarque.bera.test(na.omit(residuals(model)))
skewness(na.omit(residuals(model)))
kurtosis(na.omit(residuals(model)))
```
 
Here we can see in the decomposition plot of DLTR, that the trend of the DLTR data is constantly increasing after 2012 and there is some sort of seasonalilty. 

Based on the QQ plot, the data would be normal if we applied a ^(1/4) transformation to the response variable in our model. However, we chose not to as it increased our msfe significantly. The Shapiro- wilk test and normality test indciate that our data is not normal as the p-values are less than 0.05. Our skewness value is close to zero, indicating almost no skewness in  the data. Our kurtosis value is also not zero. 

 





**AXP**

#Part 1

```{r eval=FALSE}
#AXP
data = read_excel("MadisonPolley1.xlsx", sheet = "AXP")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)

```


#Part 2

```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "AXP")[-1,]
plot(data$Close[2600:3400])
plot(data$NegLog[2600:3400], type = 'o')
slice1 = data[2600:3395, 8]
slice1.last5 = data[(3396:3400), 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```


**BIIB**


#Part 1

```{r eval=FALSE}
#BIIB

data = read_excel("MadisonPolley1.xlsx", sheet = "BIIB")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(data_without.last.five,order=c(4,2,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
```

#Part 2

```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "BIIB")[-1,]
plot(data$Close)
plot(data$Close[750:1700])
plot(data$NegLog[750:1700], type = 'o')
slice1 = data[750:1695, 8]
slice1.last5 = data[1696:1700, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
```

**BKNG**

#Part 1

```{r eval=FALSE}
#BKNG

data = read_excel("MadisonPolley1.xlsx", sheet = "BKNG")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(data_without.last.five,order=c(4,0,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals ,order=c(0,2))
summary(g)
plot(g$residuals)

```

#Part 2

```{r eval=FALSE}
#BKNG

data = read_excel("MadisonPolley1.xlsx", sheet = "BKNG")[-1,]
plot(data$Close)
plot(data$Close[0:1600])
plot(data$NegLog[0:1600], type = 'o')
slice1 = data[0:1595, 8]
slice1.last5 = data[1596:1600, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

**BLK**

#Part 1

```{r eval=FALSE}

#BLK

data = read_excel("MadisonPolley1.xlsx", sheet = "BLK")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)


#fit ARMA
model=arima(data_without.last.five,order=c(5,2,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals ,order=c(0,2))
summary(g)
plot(g$residuals)

```


#Part 2

```{r eval=FALSE}
#BLK

data = read_excel("MadisonPolley1.xlsx", sheet = "BLK")[-1,]
plot(data$Close)
plot(data$Close[500:1600])
plot(data$NegLog[500:1600], type = 'o')
slice1 = data[500:1595, 8]
slice1.last5 = data[1596:1600, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

**CVS**

#Part 1

```{r eval=FALSE}
#CVS

data = read_excel("MadisonPolley1.xlsx", sheet = "CVS")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(data_without.last.five,order=c(2,0,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals ,order=c(0,2))
summary(g)
plot(g$residuals)
```
#Part 2

```{r eval=FALSE}
#CVS

data = read_excel("MadisonPolley1.xlsx", sheet = "CVS")[-1,]
plot(data$Close)
plot(data$Close[1200:2000])
plot(data$NegLog[1200:2000], type = 'o')
slice1 = data[1200:1995, 8]
slice1.last5 = data[1996:2000, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

**DHR**

#Part 1

```{r eval=FALSE}
#DHR

data = read_excel("MadisonPolley1.xlsx", sheet = "DHR")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(data_without.last.five,order=c(0,0,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals ,order=c(0,1))
summary(g)
plot(g$residuals)
```

#Part 2

```{r eval=FALSE}
#DHR

data = read_excel("MadisonPolley1.xlsx", sheet = "DHR")[-1,]
plot(data$Close)
plot(data$Close[1000:2000])
plot(data$NegLog[1000:2000], type = 'o')
slice1 = data[1000:1995, 8]
slice1.last5 = data[1996:2000, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(1,0,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

**EXC**

#Part 1


```{r eval=FALSE}
#EXC

data = read_excel("MadisonPolley1.xlsx", sheet = "EXC")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(data_without.last.five,order=c(3,1,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals ,order=c(0,1))
summary(g)
plot(g$residuals)

```

#Part 2

```{r eval=FALSE}
#EXC

data = read_excel("MadisonPolley1.xlsx", sheet = "EXC")[-1,]
plot(data$Close)
plot(data$Close[2600:3100])
plot(data$NegLog[2600:3100], type = 'o')
slice1 = data[2600:3095, 8]
slice1.last5 = data[3096:3100, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(2,1,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```

**GOOG**

#Part 1

```{r eval=FALSE}

#GOOG

data = read_excel("MadisonPolley1.xlsx", sheet = "GOOG")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(data_without.last.five,order=c(3,2,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals ,order=c(0,1))
summary(g)
plot(g$residuals)

```


#Part 2

```{r eval=FALSE}
#GOOG

data = read_excel("MadisonPolley1.xlsx", sheet = "GOOG")[-1,]
plot(data$Close)
plot(data$Close[2800:3500])
plot(data$NegLog[2800:3500], type = 'o')
slice1 = data[2800:3495, 8]
slice1.last5 = data[3496:3500, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
acf(g$residuals[3:length(g$residuals)])
pacf(g$residuals[3:length(g$residuals)])
```



# Part 1 MA

```{r eval=FALSE}
#MA
data = read_excel("MadisonPolley1.xlsx", sheet = "MA")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(2,0,1))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
```

# Part 2

```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "MA")[-1,]
plot(data$Close)
plot(data$NegLog[0:2500], type = 'o')
slice1 = data[0:2500, 8]
slice1.last5 = data[2501:2505, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
```

# Part 1 MDLZ

```{r eval=FALSE}
#MDLZ
data = read_excel("MadisonPolley1.xlsx", sheet = "MDLZ")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(2,1,4))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
```

# Part 2

```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "MDLZ")[-1,]
plot(data$Close)
plot(data$NegLog[2600:3200], type = 'o')
slice1 = data[2600:3200, 8]
slice1.last5 = data[3201:3205, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(1,1,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
```

# Part 1 MO

```{r eval=FALSE}
#MO
data = read_excel("MadisonPolley1.xlsx", sheet = "MO")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,1,1))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
```

# Part 2

```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "MO")[-1,]
plot(data$Close)
plot(data$NegLog[900:2500], type = 'o')
slice1 = data[900:2500, 8]
slice1.last5 = data[2501:2505, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

# Part 1 SBUX

```{r eval=FALSE}
#SBUX
data = read_excel("MadisonPolley1.xlsx", sheet = "SBUX")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,1,2))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
```

# Part 2

```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "SBUX")[-1,]
plot(data$Close)
plot(data$NegLog[900:2400], type = 'o')
slice1 = data[900:2400, 8]
slice1.last5 = data[2401:2405, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(2,1,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

# Part 1 ZION

```{r eval=FALSE}
#ZION
data = read_excel("MadisonPolley1.xlsx", sheet = "ZION")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(2,2,4))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
```

# Part 2

```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "ZION")[-1,]
plot(data$Close)
plot(data$NegLog[2500:3000], type = 'o')
slice1 = data[2500:3000, 8]
slice1.last5 = data[3001:3005, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
```

# Part 1 VMC

```{r eval=FALSE}
#VMC
data = read_excel("MadisonPolley1.xlsx", sheet = "VMC")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,2,4))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
```

# Part 2

```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "VMC")[-1,]
plot(data$Close)
plot(data$NegLog[1500:2600], type = 'o')
slice1 = data[1500:2600, 8]
slice1.last5 = data[2601:2605, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,2))
summary(g)
plot(g$residuals)
```

# Part 1 VLO

```{r eval=FALSE}
#VLO
data = read_excel("MadisonPolley1.xlsx", sheet = "VLO")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(16,1,0))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
```

# Part 2

```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "VLO")[-1,]
plot(data$Close)
plot(data$NegLog[1000:2300], type = 'o')
slice1 = data[1000:2300, 8]
slice1.last5 = data[2301:2305, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,2))
summary(g)
plot(g$residuals)
```

# Part 1 TSN

```{r eval=FALSE}
#TSN
data = read_excel("MadisonPolley1.xlsx", sheet = "TSN")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,2,2))
coeftest(model)
model

acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
```

# Part 2

```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "TSN")[-1,]
plot(data$Close)
plot(data$NegLog[800:2500], type = 'o')
slice1 = data[800:2500, 8]
slice1.last5 = data[2501:2505, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(1,1,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```


# SNA Part 1
```{r eval=FALSE}
#SNA
#Part 1

data = read_excel("MadisonPolley1.xlsx", sheet = "SNA")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,0,0))
coeftest(model)
model
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,2))
summary(g)
plot(g$residuals)
```

# SNA Part 2
```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "SNA")[-1,]
data
plot(data$Close)
plot(data$NegLog[1400:2400], type = 'o')
slice1 = data[1400:2400, 8]
slice1.last5 = data[2401:2405, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)


```

# NCLH Part 1
```{r eval=FALSE}
#NCLH

data = read_excel("MadisonPolley1.xlsx", sheet = "NCLH")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,1,1))
coeftest(model)
model
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)

```

# NCLH Part 2
```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "NCLH")[-1,]
plot(data$Close)
plot(data$NegLog[450:1000], type = 'o')
slice1 = data[450:1000, 8]
slice1.last5 = data[1001:1005, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)
```

# MAA Part 1
```{r eval=FALSE}
#MAA
data = read_excel("MadisonPolley1.xlsx", sheet = "MAA")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,1))
summary(g)
plot(g$residuals)

```

# MAA Part 2
```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "MAA")[-1,]
plot(data$Close)
plot(data$NegLog[1000:2800], type = 'o')
slice1 = data[1000:2800, 8]
slice1.last5 = data[2801:2805, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
model
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

# MDT Part 1
```{r eval=FALSE}
#MDT
data = read_excel("MadisonPolley1.xlsx", sheet = "MDT")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(0,2,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,2))
summary(g)
plot(g$residuals)
```

# MDT Part 2
```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "MDT")[-1,]
plot(data$Close)
plot(data$NegLog[1000:3000], type = 'o')
slice1 = data[1000:3000, 8]
slice1.last5 = data[3001:3005, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
```

# JNPR Part 1
```{r eval=FALSE}
#JNPR
data = read_excel("MadisonPolley1.xlsx", sheet = "JNPR")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(3,1,3))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
```

# JNPR Part 2
```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "JNPR")[-1,]
plot(data$Close)
plot(data$NegLog[1500:3500], type = 'o')
slice1 = data[1500:3500, 8]
slice1.last5 = data[3501:3505, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,1,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

# FE Part 1
```{r eval=FALSE}
#FE

data = read_excel("MadisonPolley1.xlsx", sheet = "FE")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

# FE Part 2
```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "FE")[-1,]
plot(data$Close)
plot(data$NegLog[500:3000], type = 'o')
slice1 = data[500:3000, 8]
slice1.last5 = data[3001:3005, 8]
acf(slice1)
pacf(slice1)

#auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,0))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```

# EA Part 1
```{r eval=FALSE}
#EA
data = read_excel("MadisonPolley1.xlsx", sheet = "EA")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,0,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)

```

# EA Part 2
```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "EA")[-1,]
plot(data$Close)
plot(data$NegLog[1700:3747], type = 'o')
slice1 = data[1700:3747, 8]
slice1.last5 = data[3748:3752, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,1))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)
```

# DLTR Part 1
```{r eval=FALSE}
#DLTR
data = read_excel("MadisonPolley1.xlsx", sheet = "DLTR")[-1,8]

#Split the last five values
data_last.five=data[((nrow(data))-4):(nrow(data)),]
data_last.five=data_last.five$NegLog

data_without.last.five=data[1:(nrow(data)-5),]
data_without.last.five=data_without.last.five$NegLog

acf(data_without.last.five)
pacf(data_without.last.five)

#auto.arima(data_without.last.five, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA(2,0)
model=arima(data_without.last.five,order=c(1,2,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = data_last.five, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(1,1))
summary(g)
plot(g$residuals)

````

# DLTR Part 2
```{r eval=FALSE}
data = read_excel("MadisonPolley1.xlsx", sheet = "DLTR")[-1,]
plot(data$Close)
plot(data$NegLog[0:1500], type = 'o')
slice1 = data[0:1500, 8]
slice1.last5 = data[1501:1505, 8]
acf(slice1)
pacf(slice1)

auto.arima(slice1, max.p = 10, max.q = 10, max.d = 2)

#fit ARMA
model=arima(slice1,order=c(0,0,2))
coeftest(model)
acf(model$residuals)
pacf(model$residuals)

#predict the last five
forecast=predict(model,n.ahead=5)$pred

#See the forecasting
fore=data.frame(actual = slice1.last5$NegLog, forecast = forecast, error = (forecast - data_last.five))

#MSFE
MSFE = sum((fore$forecast-fore$actual)^2)/5
MSFE

#GARCH
g = garch(model$residuals, order=c(0,2))
summary(g)
plot(g$residuals)
```











